"""
AI Agent Core - Main AIAgent class with core functionality
Simplified and modular design using specialized service classes
"""

import os
import random
import threading
import time
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional

from openai import OpenAI

from .ai_models import Message, ConversationContext
from .ai_audio import AIAudioService
from .ai_intervention import AIInterventionService
from .ai_code_analysis import AICodeAnalysisService
from .ai_reflection import get_reflection_service
from database.models import ChatMessage


class AIAgent:
    def __init__(self, socketio_instance):
        # Check if OpenAI API key is available
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("‚ö†Ô∏è  Warning: No OpenAI API key found. AI agent will be disabled.")
            print("   Set OPENAI_API_KEY in your .env file to enable AI responses.")
            self.client = None
        else:
            try:
                self.client = OpenAI(api_key=api_key)
                print("‚úÖ AI Agent (Bob) initialized successfully!")
            except Exception as e:
                print(f"‚ùå Error initializing OpenAI client: {e}")
                print("   AI agent will be disabled.")
                self.client = None
        
        self.socketio = socketio_instance
        self.conversation_history = {}  # room_id -> ConversationContext
        self.room_ai_modes = {}  # room_id -> ai_mode (shared, shared_no_voice, individual, none)
        
        # AI Agent identity
        self.agent_name = "Bob (AI Assistant)"
        self.agent_id = "ai_agent_bob"
        
        # Initialize specialized services
        self.audio_service = AIAudioService(
            socketio_instance, self.client, self.agent_name, self.agent_id
        )
        
        self.intervention_service = AIInterventionService(
            ai_decision_callback=self._centralized_ai_decision,
            send_message_callback=self.send_ai_message,
            get_conversation_history_callback=lambda: self.conversation_history,
            send_progress_notification_callback=self.send_progress_check_notification
        )
        
        self.code_analysis_service = AICodeAnalysisService(
            self.client, socketio_instance
        )
        
        # Reflection service will be obtained when needed (it may not be initialized yet)
        self.reflection_service = None

    def _save_message_to_db_async(self, message: Message, context: 'ConversationContext'):
        """Save message to MongoDB asynchronously"""
        print("Saving message to DB async...", message)  # Debug print
        def save_to_db():
            try:
                # Determine if this is an AI message
                is_ai_message = message.userId == self.agent_id
                
                # Parse timestamp - handle both string and datetime
                if isinstance(message.timestamp, str):
                    # Try to parse ISO format timestamp
                    try:
                        timestamp = datetime.fromisoformat(message.timestamp.replace('Z', '+00:00'))
                    except:
                        # Fallback to current time if parsing fails
                        timestamp = datetime.utcnow()
                else:
                    timestamp = message.timestamp if message.timestamp else datetime.utcnow()
                
                # Increment message counter
                context.message_counter += 1
                
                # Generate session ID if not exists
                if not context.session_id:
                    context.session_id = f"{context.room_id}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}"
                
                # Create database record using fields from message
                chat_message = ChatMessage(
                    message_id=str(message.id),
                    content=message.content,
                    username=message.username,
                    user_id=message.userId,
                    room_id=message.room,
                    session_id=context.session_id,
                    message_number=context.message_counter,
                    timestamp=timestamp,
                    is_auto_generated=message.isAutoGenerated,
                    is_ai_message=is_ai_message,
                    ai_trigger_type=message.ai_trigger_type if is_ai_message else None,
                    is_reflection=message.is_reflection
                )
                
                # Save to database
                chat_message.save()
                print(f"üíæ Saved message #{context.message_counter} to MongoDB: {message.username[:20]} in session {context.session_id}")
                
            except Exception as e:
                print(f"‚ùå Error saving message to database: {e}")
                # Don't let database errors break the chat functionality
                pass
        
        # Run in a separate thread to avoid blocking
        threading.Thread(target=save_to_db, daemon=True).start()

    def _extract_todo_type(self, todo_line: str) -> str:
        """Extract the type/purpose of the TODO comment"""
        todo_lower = todo_line.lower()
        if 'implement' in todo_lower or 'write' in todo_lower:
            return 'implementation'
        elif 'fix' in todo_lower or 'bug' in todo_lower:
            return 'bug_fix'
        elif 'optimize' in todo_lower or 'improve' in todo_lower:
            return 'optimization'
        elif 'test' in todo_lower:
            return 'testing'
        elif 'add' in todo_lower:
            return 'feature_addition'
        else:
            return 'general'

    def _save_tracking_message_to_db_async(self, content: str, room_id: str, ai_trigger_type: str, username: str = None, extra_data: dict = None):
        """Save AI tracking message directly to database without adding to conversation context"""
        def save_to_db():
            try:
                # Get session context for session_id and message counter
                context = self.conversation_history.get(room_id)
                if not context:
                    # Create minimal context if it doesn't exist
                    context = ConversationContext(messages=[], room_id=room_id)
                    self.conversation_history[room_id] = context
                
                # Generate session ID if not exists
                if not context.session_id:
                    context.session_id = f"{context.room_id}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}"
                
                # Increment message counter for proper sequencing
                context.message_counter += 1
                
                # Create database record for tracking message
                chat_message = ChatMessage(
                    message_id=f"tracking_{ai_trigger_type}_{int(time.time() * 1000)}",
                    content=content,
                    username=username or self.agent_name,
                    user_id=self.agent_id,
                    room_id=room_id,
                    session_id=context.session_id,
                    message_number=context.message_counter,
                    timestamp=datetime.utcnow(),
                    is_auto_generated=True,
                    is_ai_message=True,
                    ai_trigger_type=ai_trigger_type,
                    is_reflection=False,
                    extra_data=extra_data or {}
                )
                
                # Save to database
                chat_message.save()
                print(f"üìä Saved tracking message #{context.message_counter} to MongoDB: {ai_trigger_type} in session {context.session_id}")
                
            except Exception as e:
                print(f"‚ùå Error saving tracking message to database: {e}")
                # Don't let database errors break the functionality
                pass
        
        # Run in a separate thread to avoid blocking
        threading.Thread(target=save_to_db, daemon=True).start()

    def track_code_analysis(self, room_id: str, analysis_type: str, code_block: str, language: str, analysis_result: dict = None):
        """Track code analysis activity with complete context"""
        print(f"Tracking code analysis ({analysis_type}) for room {room_id}")
        
        # Build comprehensive tracking content
        tracking_content = {
            "activity_type": "code_analysis",
            "analysis_type": analysis_type,
            "language": language,
            "code_block": code_block,
            "code_length": len(code_block),
            "analysis_result": analysis_result or {},
            "issues_found": len(analysis_result.get('issues', [])) if analysis_result else 0,
            "suggestions_provided": len(analysis_result.get('suggestions', [])) if analysis_result else 0
        }
        
        content_summary = f"Code Analysis ({analysis_type}): {language} code ({len(code_block)} chars) - Found {tracking_content['issues_found']} issues, {tracking_content['suggestions_provided']} suggestions"
        
        self._save_tracking_message_to_db_async(
            content=content_summary,
            room_id=room_id,
            ai_trigger_type='code_analysis',
            username="AI Code Analysis",
            extra_data=tracking_content
        )

    def track_scaffolding_activity(self, room_id: str, comment_line: str, language: str, scaffolding_result: dict = None):
        """Track task scaffolding activity with complete context"""
        # Build comprehensive tracking content
        tracking_content = {
            "activity_type": "scaffolding",
            "language": language,
            "original_comment": comment_line,
            "scaffolding_generated": scaffolding_result.get('hasScaffolding', False) if scaffolding_result else False,
            "scaffolding_code": scaffolding_result.get('scaffoldingCode', '') if scaffolding_result else '',
            "hint_provided": scaffolding_result.get('hint', '') if scaffolding_result else '',
            "scaffolding_lines": len(scaffolding_result.get('scaffoldingCode', '').split('\n')) if scaffolding_result and scaffolding_result.get('scaffoldingCode') else 0
        }
        
        content_summary = f"Task Scaffolding: {language} - '{comment_line}' -> {'Generated' if tracking_content['scaffolding_generated'] else 'No scaffolding'} ({tracking_content['scaffolding_lines']} lines)"
        
        self._save_tracking_message_to_db_async(
            content=content_summary,
            room_id=room_id,
            ai_trigger_type='task_scaffolding',
            username="AI Scaffolding",
            extra_data=tracking_content
        )

    def track_todo_reveal(self, room_id: str, todo_line: str, language: str, todo_result: dict = None):
        """Track TODO reveal activity with complete context"""
        # Build comprehensive tracking content
        tracking_content = {
            "activity_type": "todo_reveal",
            "language": language,
            "original_todo": todo_line,
            "todo_success": todo_result.get('success', False) if todo_result else False,
            "generated_code": todo_result.get('generatedCode', '') if todo_result else '',
            "explanation": todo_result.get('explanation', '') if todo_result else '',
            "generated_lines": len(todo_result.get('generatedCode', '').split('\n')) if todo_result and todo_result.get('generatedCode') else 0,
            "todo_type": self._extract_todo_type(todo_line)
        }
        
        content_summary = f"TODO Revealed: {language} - '{todo_line}' -> {'Success' if tracking_content['todo_success'] else 'Failed'} ({tracking_content['generated_lines']} lines generated)"
        
        self._save_tracking_message_to_db_async(
            content=content_summary,
            room_id=room_id,
            ai_trigger_type='todo_reveal',
            username="AI TODO",
            extra_data=tracking_content
        )

    def track_code_execution_analysis(self, room_id: str, code: str, language: str, execution_result: dict, analysis_result: dict = None):
        """Track code execution analysis with complete context"""
        # Build comprehensive tracking content
        tracking_content = {
            "activity_type": "code_execution_analysis",
            "language": language,
            "executed_code": code,
            "code_length": len(code),
            "execution_output": execution_result.get('output', ''),
            "execution_error": execution_result.get('error', ''),
            "execution_success": execution_result.get('success', True),
            "execution_time_ms": execution_result.get('executionTime', 0),
            "exit_code": execution_result.get('exitCode', 0),
            "analysis_provided": analysis_result is not None,
            "analysis_result": analysis_result or {}
        }
        
        status = "Success" if tracking_content['execution_success'] else "Error"
        content_summary = f"Code Execution Analysis: {language} code ({len(code)} chars) -> {status} in {tracking_content['execution_time_ms']}ms"
        if tracking_content['execution_error']:
            content_summary += f" - Error: {tracking_content['execution_error'][:50]}..."
        
        self._save_tracking_message_to_db_async(
            content=content_summary,
            room_id=room_id,
            ai_trigger_type='code_execution_analysis',
            username="AI Execution Analysis",
            extra_data=tracking_content
        )

    def track_enter_event(self, room_id: str, current_line: str, line_number: int, language: str, user_id: str = None, full_code: str = None):
        """Track enter key press events in the code editor with current line context"""
        print(f"Tracking enter event for room {room_id} at line {line_number}")
        print(f"  Current line: '{current_line}' (length: {len(current_line)})")
        print(f"  Full code length: {len(full_code) if full_code else 0} characters")
        
        # Analyze the line content
        is_empty_line = len(current_line.strip()) == 0
        is_whitespace_only = len(current_line) > 0 and len(current_line.strip()) == 0
        
        # Build comprehensive tracking content
        tracking_content = {
            "activity_type": "enter_event",
            "language": language,
            "current_line": current_line,
            "current_line_trimmed": current_line.strip(),
            "line_number": line_number,
            "user_id": user_id or "unknown",
            "full_code": full_code or "",
            "code_length": len(full_code) if full_code else 0,
            "current_line_length": len(current_line),
            "current_line_trimmed_length": len(current_line.strip()),
            "is_empty_line": is_empty_line,
            "is_whitespace_only": is_whitespace_only,
            "has_meaningful_content": len(current_line.strip()) > 0
        }
        
        # Create a more descriptive summary
        if is_empty_line:
            line_description = "empty line"
        elif is_whitespace_only:
            line_description = f"whitespace-only line ({len(current_line)} spaces/tabs)"
        else:
            line_description = f"'{current_line.strip()}'"
        
        content_summary = f"Enter Event: Line {line_number} - {line_description} (Code: {tracking_content['code_length']} chars)"
        
        self._save_tracking_message_to_db_async(
            content=content_summary,
            room_id=room_id,
            ai_trigger_type='enter_event',
            username=f"Code Editor ({user_id or 'User'})",
            extra_data=tracking_content
        )

    def get_session_messages(self, session_id: str, limit: int = None) -> List[Dict]:
        """Retrieve all messages for a session from MongoDB"""
        try:
            query = ChatMessage.objects(session_id=session_id).order_by('message_number')
            if limit:
                query = query.limit(limit)
            
            messages = [msg.to_dict() for msg in query]
            print(f"üìö Retrieved {len(messages)} messages for session {session_id}")
            return messages
            
        except Exception as e:
            print(f"‚ùå Error retrieving session messages: {e}")
            return []

    def get_room_messages(self, room_id: str, limit: int = 50) -> List[Dict]:
        """Retrieve recent messages for a room from MongoDB"""
        try:
            query = ChatMessage.objects(room_id=room_id).order_by('-timestamp')
            if limit:
                query = query.limit(limit)
            
            messages = [msg.to_dict() for msg in query]
            # Return in chronological order (oldest first)
            messages.reverse()
            print(f"üìö Retrieved {len(messages)} recent messages for room {room_id}")
            return messages
            
        except Exception as e:
            print(f"‚ùå Error retrieving room messages: {e}")
            return []

    def get_ai_messages_by_trigger(self, room_id: str = None, ai_trigger_type: str = None, limit: int = 50) -> List[Dict]:
        """Retrieve AI messages by trigger type for analysis"""
        try:
            # Build query filters
            filters = {'is_ai_message': True}
            if room_id:
                filters['room_id'] = room_id
            if ai_trigger_type:
                filters['ai_trigger_type'] = ai_trigger_type
            
            query = ChatMessage.objects(**filters).order_by('-timestamp')
            if limit:
                query = query.limit(limit)
            
            messages = [msg.to_dict() for msg in query]
            print(f"üìä Retrieved {len(messages)} AI messages (trigger: {ai_trigger_type}, room: {room_id})")
            return messages
            
        except Exception as e:
            print(f"‚ùå Error retrieving AI messages by trigger: {e}")
            return []

    def get_conversation_stats(self, room_id: str = None, session_id: str = None) -> Dict:
        """Get conversation statistics for analytics"""
        try:
            # Build base query
            filters = {}
            if room_id:
                filters['room_id'] = room_id
            if session_id:
                filters['session_id'] = session_id
            
            messages = ChatMessage.objects(**filters)
            
            stats = {
                'total_messages': messages.count(),
                'user_messages': messages.filter(is_ai_message=False).count(),
                'ai_messages': messages.filter(is_ai_message=True).count(),
                'ai_trigger_breakdown': {},
                'conversation_duration': None,
                'average_response_time': None
            }
            
            # Get AI trigger type breakdown
            ai_messages = messages.filter(is_ai_message=True)
            for msg in ai_messages:
                trigger = msg.ai_trigger_type or 'unknown'
                stats['ai_trigger_breakdown'][trigger] = stats['ai_trigger_breakdown'].get(trigger, 0) + 1
            
            # Calculate conversation duration
            if messages.count() > 0:
                first_msg = messages.order_by('timestamp').first()
                last_msg = messages.order_by('-timestamp').first()
                if first_msg and last_msg:
                    duration = (last_msg.timestamp - first_msg.timestamp).total_seconds()
                    stats['conversation_duration'] = duration
            
            print(f"üìà Generated conversation stats: {stats}")
            return stats
            
        except Exception as e:
            print(f"‚ùå Error generating conversation stats: {e}")
            return {}

    def get_user_conversation_history(self, user_id: str, limit: int = 100) -> List[Dict]:
        """Get all conversations for a specific user across all rooms"""
        try:
            query = ChatMessage.objects(user_id=user_id).order_by('-timestamp')
            if limit:
                query = query.limit(limit)
            
            messages = [msg.to_dict() for msg in query]
            print(f"üë§ Retrieved {len(messages)} messages for user {user_id}")
            return messages
            
        except Exception as e:
            print(f"‚ùå Error retrieving user conversation history: {e}")
            return []

    def search_messages(self, query_text: str, room_id: str = None, user_id: str = None, limit: int = 50) -> List[Dict]:
        """Search messages by content"""
        try:
            # Build MongoDB text search query
            filters = {'content__icontains': query_text}  # Case-insensitive substring search
            
            if room_id:
                filters['room_id'] = room_id
            if user_id:
                filters['user_id'] = user_id
            
            query = ChatMessage.objects(**filters).order_by('-timestamp')
            if limit:
                query = query.limit(limit)
            
            messages = [msg.to_dict() for msg in query]
            print(f"üîç Found {len(messages)} messages containing '{query_text}'")
            return messages
            
        except Exception as e:
            print(f"‚ùå Error searching messages: {e}")
            return []

    def _centralized_ai_decision(self, room_id: str, is_reflection: bool = False, is_progress_check: bool = False, is_manual_progress: bool = False) -> tuple[bool, str]:
        """Central AI decision making: Should intervene and what to say"""
        if not self.client:
            print("üö´ AI WILL NOT INTERVENE: No LLM client available")
            return False, ""
        
        context = self.conversation_history.get(room_id)
        if not context:
            return False, ""

        # Handle reflection mode
        if is_reflection:
            # Get reflection service dynamically (it may not have been initialized during __init__)
            if not self.reflection_service:
                self.reflection_service = get_reflection_service()
            
            if self.reflection_service:
                response = self.reflection_service.generate_reflection_response_sync(
                    room_id, self.conversation_history
                )
            else:
                print("‚ùå Error: Reflection service not available")
                response = "What did you learn today?"
            return True, response if response else "What did you learn today?"
        
        # Handle 30-second progress check
        if is_progress_check:
            if is_manual_progress:
                return self._handle_manual_progress_check(room_id, context)
            else:
                return self._handle_progress_check(room_id, context)

        # Get recent conversation context (last 5 messages)
        recent_messages = context.messages[-10:] if len(context.messages) >= 10 else context.messages
        
        # Check if the last message contains direct AI mention
        last_message = context.messages[-1] if context.messages else None
        is_direct_mention = last_message and self._is_direct_ai_mention(last_message.content)
        
        # Build AI message history context to avoid repetition
        ai_history_context = self._build_ai_history_context(context)
        
        # Create comprehensive system message combining context and instructions
        problem_info = f"Problem: {context.problem_title or 'General coding'}"
        if context.problem_description:
            problem_info += f" - {context.problem_description}"
        
        code_info = f"Current code:\n{context.code_context}" if context.code_context else "No code visible yet"
        
        # Check if user is asking for syntax/code
        is_asking_for_syntax = last_message and any(keyword in last_message.content.lower() for keyword in ['syntax', 'example', 'code', 'documentation'])
        
        # Build comprehensive system message
        if is_direct_mention:
            system_message = f"""You are Bob, an AI pair programming assistant focused on LEARNING. The user has directly mentioned you with @AI or similar keyword.

{problem_info}
Language: {context.programming_language}

{code_info}

{ai_history_context}

LEARNING APPROACH:
- Help users when they need it, but avoid unnecessary responses when they're satisfied
- When users say 'I'm not sure', 'I need help', or ask questions, provide helpful guidance
- When they say 'okay', 'thanks', 'got it', you can choose not to respond
- CRITICAL: Look at your recent messages above - you CANNOT repeat the same type of response
- Each message must be more concrete than the previous if they still need help
- Balance learning with being actually helpful
{"- Can show small syntax examples when users need concrete help" if is_asking_for_syntax else "- Focus on brief conceptual hints rather than code snippets"}

Provide a helpful response (10-30 words) or choose not to respond if they seem satisfied."""

        else:
            system_message = f"""You are Bob, an AI pair programming assistant focused on LEARNING.

{problem_info}
Language: {context.programming_language}

{code_info}

{ai_history_context}

INTERVENTION APPROACH:
- Help users when they need it, but avoid unnecessary responses when they're satisfied
- When users say 'I'm not sure', 'I need help', or ask questions, provide helpful guidance
- When they say 'okay', 'thanks', 'got it', return "NO_RESPONSE"
- CRITICAL: Look at your recent messages above - you CANNOT repeat the same type of response
- Each response must be MORE CONCRETE than your previous ones if they still need help
- NEVER end responses with questions like "Need help with...?" or "Want me to...?"
{"- Can show small syntax examples when users need concrete help" if is_asking_for_syntax else "- Focus on brief conceptual hints rather than code snippets"}

Return EXACTLY "NO_RESPONSE" (if no response needed) OR provide a helpful response (10-30 words)."""

        # Convert conversation to proper message format
        messages = [{"role": "system", "content": system_message}]
        
        # Add recent conversation messages in proper format
        for msg in recent_messages:
            if msg.userId == 'ai_agent_bob':
                messages.append({"role": "assistant", "content": msg.content})
            else:
                messages.append({"role": "user", "content": f"{msg.username}: {msg.content}"})

        print("üîç AI Decision - System message:", system_message[:200], "...")
        print(f"üîç AI Decision - Message count: {len(messages)} messages")
        print(messages)
        try:
            response = self.client.chat.completions.create(
                model="gpt-4.1-mini",
                messages=messages,
                max_tokens=90 if is_direct_mention else 60,
                temperature=0.7
            )
            
            llm_response = response.choices[0].message.content.strip()
            
            # Handle NO_RESPONSE for idle interventions (but not direct mentions)
            if llm_response == "NO_RESPONSE" and not is_direct_mention:
                print(f"üö´ AI chose not to intervene: User seems satisfied/working independently")
                return False, ""
            
            # Always respond with whatever the LLM generates (no YES/NO parsing)
            if llm_response and llm_response != "NO_RESPONSE":
                mention_type = "DIRECT MENTION" if is_direct_mention else "IDLE INTERVENTION"
                print(f"‚úÖ AI WILL INTERVENE ({mention_type}): {llm_response[:50]}...")
                return True, llm_response
            else:
                mention_type = "direct mention" if is_direct_mention else "idle period"
                print(f"üö´ AI generated empty response for {mention_type}")
                return False, ""
                
        except Exception as e:
            print(f"‚ùå Error in AI decision: {e}")
            return False, ""

    def _handle_progress_check(self, room_id: str, context: ConversationContext) -> tuple[bool, str]:
        """Handle 30-second progress check intervention"""
        return self._handle_progress_check_internal(room_id, context, is_manual=False)

    def _handle_manual_progress_check(self, room_id: str, context: ConversationContext) -> tuple[bool, str]:
        """Handle manual progress check - always returns feedback"""
        return self._handle_progress_check_internal(room_id, context, is_manual=True)

    def _handle_progress_check_internal(self, room_id: str, context: ConversationContext, is_manual: bool = False) -> tuple[bool, str]:
        """Internal method to handle progress checks"""
        try:
            # Build conversation context (last 8 messages for better context)
            recent_conversation = ""
            for msg in context.messages[-10:]:
                recent_conversation += f"{msg.username}: {msg.content}\n"
            
            # Build current state context
            current_code = context.code_context if context.code_context else "No code written yet"
            problem_info = f"Title: {context.problem_title or 'Not specified'}\nDescription: {context.problem_description or 'Not specified'}"
            
            # Build AI message history context to avoid repetition
            ai_history_context = self._build_ai_history_context(context)
            
            # Create progress check prompt
            manual_instruction = """
**MANUAL PROGRESS CHECK**: This was triggered manually by the user - ALWAYS provide feedback!
For manual checks, even if users are doing well, provide encouraging and specific feedback about their progress.
""" if is_manual else ""
            
            prompt = f"""You are Bob, an AI pair programming assistant. You're doing a progress check to see if users are on track.
{manual_instruction}
Problem Context:
{problem_info}
Language: {context.programming_language}

Current Code:
{current_code}

Recent Conversation (last 10 messages):
{recent_conversation}

{ai_history_context}

PROGRESS CHECK TASK:
Analyze if the users are making good progress toward solving the problem. Look for:

RED FLAGS (should intervene):
- Discussing completely wrong approach
- Stuck on same issue repeatedly 
- Silent for too long while having an active problem
- Code going in wrong direction vs problem requirements
- Misunderstanding fundamental concepts
- One person dominating, other not participating

GREEN FLAGS ({"provide positive feedback" if is_manual else "don't intervene"}):
- Making steady progress, even if slow
- Having productive discussions about approach
- Recently made progress or breakthroughs  
- Actively debugging and learning
- Both people contributing to conversation
- On right track even if minor issues

CRITICAL: Check your recent AI messages above - do NOT repeat the same intervention!
- If you've already given basic hints, provide more specific guidance
- If you've given specific tips, try a different approach or escalate to solution steps
- Vary your intervention type and content based on what you've said before

INTERVENTION TYPES:
- REDIRECT: "I notice you're discussing X, but for this problem you might want to consider Y instead. What do you think?"
- ENCOURAGE: "You're on the right track! Consider focusing on [specific next step]."
- FACILITATE: "What does your partner think about this approach?" or "Can you explain your idea to your partner?"
- HINT: "For this type of problem, you might want to think about [specific concept/approach]."
- POSITIVE: "Great work! You're [specific positive observation]. Keep it up!"

Response format:
- If should intervene: "YES|[intervention type]|[helpful message 15-40 words]"
- If making good progress: "{"POSITIVE|[specific positive feedback 15-40 words]" if is_manual else "NO|[reason why they're doing well 10-30 words]"}"

Your response:"""
            

            response = self.client.chat.completions.create(
                model="gpt-4.1-mini",
                messages=[
                    {"role": "system", "content": "You are a helpful pair programming assistant doing progress monitoring. Only intervene when users truly need guidance."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=120,
                temperature=0.7
            )
            
            llm_response = response.choices[0].message.content.strip()
            print(f"üìä Progress check LLM response: {llm_response}")
            
            if llm_response.startswith("YES|"):
                # Parse: YES|TYPE|MESSAGE
                parts = llm_response.split("|", 2)
                if len(parts) >= 3:
                    intervention_type = parts[1]
                    intervention_message = parts[2]
                    
                    print(f"üìä PROGRESS INTERVENTION ({intervention_type}): {intervention_message[:50]}...")
                    return True, intervention_message
                else:
                    print(f"‚ùå Progress check format error: {llm_response}")
                    return False, ""
            elif llm_response.startswith("POSITIVE|"):
                # Parse: POSITIVE|MESSAGE (for manual checks - return as positive feedback)
                parts = llm_response.split("|", 1)
                if len(parts) >= 2:
                    positive_message = parts[1]
                    print(f"üìä Manual progress check: Positive feedback - {positive_message[:50]}...")
                    return True, positive_message  # Return True so it gets sent as notification
                else:
                    print(f"‚ùå Progress check format error: {llm_response}")
                    return False, ""
            elif llm_response.startswith("NO|"):
                # Parse: NO|REASON
                parts = llm_response.split("|", 1)
                if len(parts) >= 2:
                    reason = parts[1]
                    print(f"üìä Progress check: Users making good progress in room {room_id} - Reason: {reason}")
                    # For manual checks, convert NO responses to positive feedback
                    if is_manual:
                        return True, f"Good progress! {reason}"
                    return False, ""
                else:
                    print(f"üìä Progress check: Users making good progress in room {room_id}")
                    if is_manual:
                        return True, "Good progress! You're on the right track."
                    return False, ""
            else:
                print(f"üìä Progress check: Users making good progress in room {room_id}")
                if is_manual:
                    return True, "Good progress! Keep up the good work."
                return False, ""
                
        except Exception as e:
            print(f"‚ùå Error in progress check: {e}")
            return False, ""

    def _is_direct_ai_mention(self, message_content: str) -> bool:
        """Check if message contains direct AI mention keywords"""
        # Split into words for exact word matching (more efficient and accurate)
        words = message_content.lower().split()
        
        # Single-word AI mention keywords
        ai_keywords = {
            '@ai', '@bob', 'bob', 'hey bob'
        }
        
        # Check if any word is an AI keyword
        return any(word in ai_keywords for word in words)

    # def _is_syntax_request(self, message_content: str) -> bool:
    #     """Check if message contains syntax request keywords"""
    #     content_lower = message_content.lower()
        
    #     syntax_keywords = [
    #         'syntax', 'code', 'example',
    #     ]
        
    #     return any(keyword in content_lower for keyword in syntax_keywords)

    def _build_ai_history_context(self, context: ConversationContext) -> str:
        """Build context about recent AI messages to avoid repetition"""
        print(f"üîç Building AI history context. Messages in history: {len(context.ai_message_history)}")
        for i, msg in enumerate(context.ai_message_history):
            print(f"   {i+1}. {msg[:50]}...")
            
        if not context.ai_message_history:
            return "REPETITION CHECK: No recent AI messages - this is your first intervention in a while."
        
        recent_ai_messages = context.ai_message_history[-5:]  # Last 5 AI messages
        ai_context = "REPETITION CHECK - Your Recent AI Messages (AVOID REPEATING):\n"
        for i, msg in enumerate(recent_ai_messages, 1):
            ai_context += f"  {i}. \"{msg}\"\n"
        
        # Give progressive guidance based on message count
        # message_count = len(context.ai_message_history)
        # if message_count == 0:
        #     ai_context += "GUIDANCE: First interaction - start with conceptual hints or questions."
        # elif message_count == 1:
        #     ai_context += "GUIDANCE: Second hint - MUST be more specific. Name the exact data structure (like 'use a set') or show small code snippet."
        # elif message_count == 2:
        #     ai_context += "GUIDANCE: Third hint - MUST provide concrete examples. Show actual code like 'seen = set()' or 'if num in seen:'."
        # elif message_count >= 3:
        #     ai_context += "GUIDANCE: Multiple hints given - MUST provide actual working code steps. User clearly needs concrete help."
        
        # # Important note about subtasks
        # ai_context += "\n\nIMPORTANT: This guidance level is for the CURRENT SUBTASK. If the user has moved to a different subtask or problem area, start the progression fresh (treat as first interaction for that new subtask)."
        
        return ai_context

    def _track_ai_message(self, context: ConversationContext, message: str):
        """Track AI message for progressive hints"""
        print(f"ü§ñ TRACKING AI MESSAGE: {message[:50]}...")
        print(f"   Before tracking: {len(context.ai_message_history)} messages")
        
        # Add message to history (keep last 10 messages)
        context.ai_message_history.append(message)
        if len(context.ai_message_history) > 10:
            context.ai_message_history = context.ai_message_history[-10:]
        
        print(f"   After tracking: {len(context.ai_message_history)} messages")

    def _reset_ai_message_history(self, context: ConversationContext):
        """Reset AI message history when users make progress"""
        if context.ai_message_history:
            print(f"üîÑ RESETTING AI MESSAGE HISTORY: Had {len(context.ai_message_history)} messages")
            for i, msg in enumerate(context.ai_message_history):
                print(f"   Clearing {i+1}. {msg[:50]}...")
            context.ai_message_history = []
            print(f"üîÑ Reset complete. New count: {len(context.ai_message_history)}")
        else:
            print(f"üîÑ Reset called but history was already empty")

    def _detect_user_progress(self, context: ConversationContext) -> bool:
        """Detect if users have made progress (to reset message history)"""
        # Check for positive indicators of progress:
        
        # 1. Successful code execution recently
        if (context.last_execution_time and 
            context.last_execution_time > datetime.now() - timedelta(minutes=2) and
            context.last_execution_success):
            return True
        
        # 2. User demonstrates understanding by explaining approach
        recent_messages = context.messages[-3:] if len(context.messages) >= 3 else context.messages
        for msg in recent_messages:
            # Skip AI messages
            if msg.userId == 'ai_agent_bob':
                continue
                
            msg_lower = msg.content.lower()
            
            # Look for solution explanation patterns
            understanding_patterns = [
                # Direct approach explanations
                "i'm thinking about using", "we can use", "let's use", "i'll use",
                "we can do", "i can do", "let's do", "we should",
                "basically like", "so we", "then we", "first we",
                
                # Algorithm step descriptions  
                "iterate", "loop", "check if", "add to", "put in",
                "return", "create", "initialize", "make a",
                
                # Confirmation of understanding
                "got it", "i see", "makes sense", "understood", "i get it",
                "yeah so", "okay so", "right so", "oh i see"
            ]
            
            # Check if user is explaining their approach
            if any(pattern in msg_lower for pattern in understanding_patterns):
                print(f"üß† DETECTED USER UNDERSTANDING: '{msg.content[:60]}...' - will reset AI history")
                return True
        
        # 3. Traditional progress indicators
        for msg in recent_messages:
            # Look for keywords indicating successful progress
            progress_keywords = ['works', 'working', 'fixed', 'got it', 'solved', 'success', 'good', 'nice']
            if any(keyword in msg.content.lower() for keyword in progress_keywords):
                return True
        
        # 4. No AI intervention needed for a while (users working independently)
        if (context.last_ai_response and 
            datetime.now() - context.last_ai_response > timedelta(minutes=5)):
            return True
            
        return False

    def _handle_direct_ai_mention(self, room_id: str):
        """Handle direct AI mention - respond immediately bypassing ALL restrictions"""
        context = self.conversation_history.get(room_id)
        if not context:
            return
            
        if not self.client:
            print("üö´ AI cannot respond to direct mention: No LLM client available")
            return
            
        print(f"üöÄ BYPASSING ALL RESTRICTIONS for direct AI mention in room {room_id}")
        
        # Force AI decision for direct mention (no restrictions)
        should_respond, message = self._centralized_ai_decision(room_id)
        
        if should_respond and message:
            # Update AI response timestamp (but no cooldown enforced for direct mentions)
            context.last_ai_response = datetime.now()
            
            # Send immediate AI response using proper chat message format
            self.send_ai_message(room_id, message)
            
            print(f"‚úÖ AI responded IMMEDIATELY to direct mention in room {room_id}: {message[:50]}...")
        else:
            # Even if LLM says no, we should respond to direct mentions with a helpful message
            fallback_message = "I'm here to help! What specific question do you have about your code or programming problem?"
            context.last_ai_response = datetime.now()
            self.send_ai_message(room_id, fallback_message)
            print(f"‚úÖ AI responded with fallback to direct mention in room {room_id}")

    def add_message_to_context(self, message_data: Dict[str, Any]):
        """Add a new message to the conversation context with direct AI mention detection"""
        room_id = message_data.get('room')
        if not room_id:
            return
            
        # Include ALL messages (user and AI) for reflection context
        message = Message(
            id=message_data.get('id', ''),
            content=message_data.get('content', ''),
            username=message_data.get('username', 'Unknown'),
            userId=message_data.get('userId', ''),
            timestamp=message_data.get('timestamp', ''),
            room=room_id,
            isAutoGenerated=message_data.get('isAutoGenerated', False),
            ai_trigger_type=None,  # Will be set below for AI messages
            is_reflection=message_data.get('isReflection', False)
        )
        
        if room_id not in self.conversation_history:
            self.conversation_history[room_id] = ConversationContext(
                messages=[],
                room_id=room_id
            )
            
        context = self.conversation_history[room_id]
        context.messages.append(message)
        
        # Set AI trigger type for AI messages
        if message.userId == 'ai_agent_bob':
            # This is an AI message - determine the trigger type
            if message.is_reflection:
                message.ai_trigger_type = 'reflection'
            elif message_data.get('isProgressCheck', False):
                message.ai_trigger_type = 'progress_check'
            elif len(context.messages) >= 2 and self._is_direct_ai_mention(context.messages[-2].content):
                message.ai_trigger_type = 'direct_mention'
            else:
                message.ai_trigger_type = 'idle_5s'  # Default for other AI interventions
        
        # Save message to database asynchronously
        self._save_message_to_db_async(message, context)
        
        # Track AI messages for progressive hints (only for non-reflection messages)
        if message.userId == 'ai_agent_bob' and not message_data.get('isReflection', False):
            self._track_ai_message(context, message.content)
        
        # Update last message time for 5-second idle timer
        context.last_message_time = datetime.now()
        
        # Check for user progress and reset AI message history if needed
        if message.userId != 'ai_agent_bob':  # Only for user messages
            if self._detect_user_progress(context):
                self._reset_ai_message_history(context)
        
        # Cancel any pending intervention since user is active
        self.intervention_service.cancel_intervention(room_id, "new message received")

        print(f"üí¨ New message added to context in room {room_id}: {message.content[:50]}...")
        
        # Check for direct AI mention (@AI keyword) - PRIORITY RESPONSE
        if self._is_direct_ai_mention(message.content):
            print(f"üéØ DIRECT AI MENTION detected in room {room_id}: {message.content[:50]}...")
            # Respond immediately without waiting for 5-second timer
            self._handle_direct_ai_mention(room_id)
            # DO NOT start timer for direct mentions - return early
            if len(context.messages) > 10:  # max_context_messages
                context.messages = context.messages[-10:]
            return
        
        # Trigger 30-second progress check (only if not already running)
        # Only for user messages (not AI messages)
        if message.userId != 'ai_agent_bob':
            print("üìä Triggering 30-second progress check for new message...", message)
            self.intervention_service.trigger_progress_check(room_id)
        
        # Keep only recent messages
        if len(context.messages) > 10:  # max_context_messages
            context.messages = context.messages[-10:]

    def update_code_context(self, room_id: str, code: str, language: str = "python", user_id: str = None):
        """Update the current code context for a room"""
        if room_id not in self.conversation_history:
            self.conversation_history[room_id] = ConversationContext(
                messages=[],
                room_id=room_id
            )
            
        context = self.conversation_history[room_id]
        context.code_context = code
        context.programming_language = language
        
        # Cancel pending interventions - target specific user's personal room if user_id provided
        if user_id:
            # Cancel timer for the specific user's personal room (if they're in individual mode)
            personal_room = f"{room_id}_personal_{user_id}"
            self.intervention_service.cancel_intervention(personal_room, "code update received")
            print(f"üñ•Ô∏è Code updated by user {user_id} - cancelled timer for personal room: {personal_room}")
            
            # Also cancel for the main room (for shared mode compatibility)
            self.intervention_service.cancel_intervention(room_id, "code update received")
            print(f"üñ•Ô∏è Code updated in room {room_id} - cancelled pending timer")
        else:
            # Fallback to original behavior if no user_id provided
            self.intervention_service.cancel_intervention(room_id, "code update received")
            print(f"üñ•Ô∏è Code updated in room {room_id} - cancelled pending timer")
        
        # Planning intervention has been disabled
        # if not context.planning_check_done:
        #     print(f"üîç Checking for planning intervention in room {room_id}")
        #     self._check_planning_intervention(room_id)

    def update_execution_results(self, room_id: str, code: str, output: str, error: str, success: bool):
        """Update execution results and potentially reset intervention level on success"""
        if room_id not in self.conversation_history:
            return
            
        context = self.conversation_history[room_id]
        context.last_execution_code = code
        context.last_execution_output = output
        context.last_execution_error = error
        context.last_execution_success = success
        context.last_execution_time = datetime.now()
        
        # If execution was successful, reset AI message history
        if success and not error:
            self._reset_ai_message_history(context)
            print(f"üéâ Successful execution in room {room_id} - reset AI message history")

    def update_problem_context(self, room_id: str, problem_title: str, problem_description: str):
        """Update the current problem description for a room"""
        if room_id not in self.conversation_history:
            self.conversation_history[room_id] = ConversationContext(
                messages=[],
                room_id=room_id
            )
            
        context = self.conversation_history[room_id]
        context.problem_title = problem_title
        context.problem_description = problem_description

    def should_respond(self, room_id: str) -> bool:
        """Simple decision making for AI intervention after 5-second idle"""
        return self.intervention_service.should_respond(room_id, self.conversation_history)

    def generate_response(self, room_id: str) -> Optional[str]:
        """Generate AI response using centralized decision"""
        if not self.client:
            print("‚ö†Ô∏è  Cannot generate AI response: OpenAI client not initialized")
            return None
            
        if room_id not in self.conversation_history:
            return None
            
        context = self.conversation_history[room_id]
        
        # Check if we have a pre-generated intervention message from centralized decision
        if hasattr(context, 'pending_intervention_message') and context.pending_intervention_message:
            intervention_message = context.pending_intervention_message
            
            print(f"‚úÖ USING CENTRALIZED INTERVENTION: {len(intervention_message.split())} words")
            print(f"   Preview: {intervention_message[:100]}{'...' if len(intervention_message) > 100 else ''}")
            
            # Update tracking
            context.last_ai_response = datetime.now()
            
            # Clear the pending message
            context.pending_intervention_message = None
            
            return intervention_message
        else:
            print("‚ö†Ô∏è  No centralized intervention message found")
            return None

    def send_progress_check_notification(self, room_id: str, content: str):
        """Send a progress check notification as a popup bubble instead of chat message"""
        notification = {
            'id': f"progress_check_{int(time.time() * 1000)}",
            'content': content,
            'timestamp': datetime.now().isoformat(),
            'room': room_id,
            'type': 'progress_check'
        }
        
        print(f"üìä Sending progress check notification to room {room_id}: {content[:50]}...")
        
        # Send as a special progress check notification event instead of chat_message
        self.socketio.emit('progress_check_notification', notification, room=room_id, namespace='/ws')
        
        # Add to conversation context for tracking but WITHOUT updating last_ai_response timestamp
        # This ensures progress checks don't interfere with 5-second idle intervention timing
        manual_message = {
            'id': f"ai_{int(time.time() * 1000)}",
            'content': content,
            'username': self.agent_name,
            'userId': self.agent_id,
            'timestamp': datetime.now().isoformat(),
            'room': room_id,
            'isAutoGenerated': True,
            'isProgressCheck': True  # Special flag to avoid updating last_ai_response
        }
        
        # Add to context but skip timestamp updates for progress checks
        self._add_progress_check_to_context(manual_message)

    def _add_progress_check_to_context(self, message_data: Dict[str, Any]):
        """Add progress check message to context without updating last_ai_response timestamp"""
        room_id = message_data.get('room')
        if not room_id:
            return
            
        message = Message(
            id=message_data.get('id', ''),
            content=message_data.get('content', ''),
            username=message_data.get('username', 'Unknown'),
            userId=message_data.get('userId', ''),
            timestamp=message_data.get('timestamp', ''),
            room=room_id,
            isAutoGenerated=message_data.get('isAutoGenerated', False),
            ai_trigger_type='progress_check',  # Set directly for progress check messages
            is_reflection=False
        )
        
        if room_id not in self.conversation_history:
            self.conversation_history[room_id] = ConversationContext(
                messages=[],
                room_id=room_id
            )
            
        context = self.conversation_history[room_id]
        context.messages.append(message)
        
        # Save progress check message to database asynchronously
        self._save_message_to_db_async(message, context)
        
        # DO NOT update last_ai_response timestamp for progress checks
        # DO NOT track AI message for progressive hints (to avoid interference)
        # DO NOT update last_message_time (this is for 5s idle intervention)
        
        print(f"üìä Progress check message added to context in room {room_id} (no timestamp updates)")

    def send_ai_message(self, room_id: str, content: str, is_reflection: bool = False, is_progress_check: bool = False, ai_mode: str = None):
        """Send an AI message to the chat room"""
        # Use provided ai_mode or look up the stored mode for the room
        effective_ai_mode = ai_mode if ai_mode is not None else self.get_room_ai_mode(room_id)
        
        message = self.audio_service.send_ai_message(
            room_id, content, is_reflection, False, self.conversation_history, is_progress_check, effective_ai_mode
        )
        
        # Always add AI message to conversation context, even if audio service returns None
        # (audio service may return None for async operations but still sends the message)
        if message:
            # Use the message object returned by audio service
            self.add_message_to_context(message)
        else:
            # Create a message object manually to ensure it's added to context
            manual_message = {
                'id': f"ai_{int(time.time() * 1000)}",
                'content': content,
                'username': self.agent_name,  # Use consistent agent name
                'userId': self.agent_id,
                'timestamp': datetime.now().isoformat(),
                'room': room_id,
                'isAutoGenerated': True,
                'isReflection': is_reflection,
                'isProgressCheck': is_progress_check
            }
            self.add_message_to_context(manual_message)
            print(f"ü§ñ Manually added AI message to context: {content[:50]}...")


    def process_message_sync(self, message_data: Dict[str, Any]):
        """Process a new message and potentially respond"""
        try:
            # Add message to context first
            self.add_message_to_context(message_data)
            
            room_id = message_data.get('room')
            if not room_id or room_id not in self.conversation_history:
                return
            
            # Check if this is a reflection trigger (system message starting reflection)
            if message_data.get('isReflectionTrigger', False):
                print(f"üéì Reflection trigger detected: Starting reflection response for room {room_id}")
                
                # Get reflection service dynamically
                if not self.reflection_service:
                    self.reflection_service = get_reflection_service()
                
                if self.reflection_service:
                    self.reflection_service.send_reflection_opening(room_id, self.send_ai_message)
                else:
                    print("‚ùå Error: Reflection service not available for opening")
                return
            
            # Check if this is reflection mode
            is_reflection = message_data.get('isReflectionMode', False)
            
            if is_reflection:
                print(f"üéì Reflection mode: Starting 5s timer for room {room_id}")
                # Always respond after 5s in reflection mode
                self.intervention_service.schedule_reflection_response(room_id)
                return
            
            # Regular AI logic
            # Check if this is a direct AI mention BEFORE adding to context
            is_direct_mention = self._is_direct_ai_mention(message_data.get('content', ''))
            
            # Only start timer for non-direct mentions
            if not is_direct_mention:
                # Start new 5-second idle timer
                self.intervention_service.schedule_idle_intervention(room_id)
                
        except Exception as e:
            print(f"Error processing message in AI agent: {e}")

    def handle_code_update(self, room_id: str, code: str, language: str = "python", user_id: str = None):
        """Handle code updates from the editor"""
        self.update_code_context(room_id, code, language, user_id)
        
    def handle_problem_update(self, room_id: str, problem_title: str, problem_description: str):
        """Handle problem description updates"""
        self.update_problem_context(room_id, problem_title, problem_description)

    def release_generation_lock(self, room_id: str, message_id: str = None):
        """Release AI generation lock when audio playback is complete"""
        if room_id in self.conversation_history:
            print(f"üîì Audio playback complete for room {room_id} (message: {message_id})")
        else:
            print(f"‚ö†Ô∏è AI RESPONSE LOCK: No context found for room {room_id}")

    def set_room_ai_mode(self, room_id: str, ai_mode: str):
        """Set the AI mode for a specific room"""
        self.room_ai_modes[room_id] = ai_mode
        print(f"üîÑ AI mode set to '{ai_mode}' for room {room_id}")

    def get_room_ai_mode(self, room_id: str) -> str:
        """Get the AI mode for a specific room"""
        return self.room_ai_modes.get(room_id, 'shared')

    def join_room(self, room_id: str):
        """AI agent joins a room (but doesn't send greeting until session starts)"""
        # Reset AI message history for fresh room join (regardless of OpenAI client)
        if room_id not in self.conversation_history:
            # Initialize context if it doesn't exist
            self.conversation_history[room_id] = ConversationContext(
                messages=[],
                room_id=room_id
            )
        context = self.conversation_history[room_id]
        self._reset_ai_message_history(context)
        print(f"üîÑ Reset AI message history for fresh room join: {room_id}")
        
        # Only proceed with OpenAI functionality if client is available
        if not self.client:
            print(f"‚ö†Ô∏è  Bob cannot join room {room_id}: OpenAI client not initialized")
            return
            
        print(f"ü§ñ Bob joined room {room_id} and is ready for session start")

    def send_session_start_greeting(self, room_id: str):
        """Send greeting when session is actually started"""
        if not self.client:
            print(f"‚ö†Ô∏è  Bob cannot send greeting for room {room_id}: OpenAI client not initialized")
            return
            
        # Reset AI message history for fresh session start
        if room_id not in self.conversation_history:
            # Initialize context if it doesn't exist
            self.conversation_history[room_id] = ConversationContext(
                messages=[],
                room_id=room_id
            )
        context = self.conversation_history[room_id]
        self._reset_ai_message_history(context)
        print(f"üîÑ Reset AI message history for new session in room {room_id}")
            
        # Send a greeting message when session starts
        greeting_messages = [
            "Welcome! I'm here to support your pair programming session. I'll offer technical guidance and help maintain productive collaboration.",
        ]
        
        greeting = random.choice(greeting_messages)
        
        # Send greeting after a short delay (non-blocking)
        def send_greeting():
            time.sleep(1)  # Wait 1 second before greeting
            # Use send_ai_message to ensure the greeting is added to context
            self.send_ai_message(room_id, greeting, is_reflection=False)
            
        # Start greeting in a separate thread to avoid blocking
        threading.Thread(target=send_greeting, daemon=True).start()

    def set_voice_config(self, voice: str = None, model: str = None, speed: float = None):
        """Update voice configuration for TTS"""
        self.audio_service.set_voice_config(voice, model, speed)

    def analyze_code_block(self, code: str, language: str, context: Dict[str, Any], 
                          problem_context: Optional[Dict[str, Any]] = None, 
                          room_id: Optional[str] = None) -> Dict[str, Any]:
        """Analyze a code block for potential issues and provide suggestions"""
        return self.code_analysis_service.analyze_code_block(code, language, context, problem_context, room_id)

    def start_panel_analysis(self, room_id: str, code: str, result: dict):
        """Start non-blocking AI analysis for execution panel"""
        # Update execution results and reset intervention level if successful
        output = result.get('output', '')
        error = result.get('error', '')
        success = result.get('success', True)
        self.update_execution_results(room_id, code, output, error, success)
        
        # Start the panel analysis
        self.code_analysis_service.start_panel_analysis(room_id, code, result, self.conversation_history)


    def _check_planning_intervention(self, room_id: str):
        """This function has been disabled - planning intervention removed"""
        # Setting flag to true to prevent any calls to this function
        context = self.conversation_history.get(room_id)
        if context:
            context.planning_check_done = True
        return

    def reset_room_state(self, room_id: str):
        """Reset all AI agent state for a specific room"""
        try:
            print(f"üîÑ Resetting AI agent state for room {room_id}")
            
            # Cancel any pending interventions (includes progress timers)
            self.intervention_service.cleanup_room(room_id)
            
            # Remove conversation history
            if room_id in self.conversation_history:
                del self.conversation_history[room_id]
                print(f"üóëÔ∏è Cleared conversation history for room {room_id}")
            
            # Clear code analysis tracking
            self.code_analysis_service.reset_execution_tracking(room_id)
            
            # Clear individual AI conversations for all users in this room
            from .individual_ai_service import get_individual_ai_service
            individual_ai = get_individual_ai_service()
            if individual_ai:
                individual_ai.clear_room_conversations(room_id)
            
            print(f"‚úÖ Successfully reset AI agent state for room {room_id}")
            
        except Exception as e:
            print(f"‚ùå Error resetting AI agent state for room {room_id}: {e}")

    def get_room_state_summary(self, room_id: str) -> Dict[str, Any]:
        """Get a summary of current room state for debugging"""
        try:
            context = self.conversation_history.get(room_id)
            
            summary = {
                "room_id": room_id,
                "has_context": context is not None,
                "message_count": len(context.messages) if context else 0,
                "planning_check_done": context.planning_check_done if context else False,
                "has_code_context": bool(context.code_context) if context else False,
                "has_problem_context": bool(context.problem_description or context.problem_title) if context else False,
                "last_ai_response": context.last_ai_response.isoformat() if context and context.last_ai_response else None,
                "has_pending_timer": self.intervention_service.has_pending_timer(room_id),
                # AI message tracking
                "ai_message_history_count": len(context.ai_message_history) if context else 0,
            }
            
            return summary
            
        except Exception as e:
            print(f"‚ùå Error getting room state summary: {e}")
            return {"error": str(e)}

    def manual_progress_check(self, room_id: str) -> tuple[bool, str]:
        """Manually trigger a progress check that always returns feedback"""
        try:
            context = self.conversation_history.get(room_id)
            if not context:
                return False, "No conversation context found for this room."
            
            # Use the centralized AI decision with manual progress flag
            return self._centralized_ai_decision(room_id, is_progress_check=True, is_manual_progress=True)
            
        except Exception as e:
            print(f"‚ùå Error in manual progress check: {e}")
            return False, f"Error performing progress check: {str(e)}"

    # Progress tracking methods
    # Progress tracking methods
    def cancel_progress_check(self, room_id: str, reason: str):
        """Cancel 30-second progress tracking for a room"""
        self.intervention_service.cancel_progress_check(room_id, reason)
    
    def has_progress_timer(self, room_id: str) -> bool:
        """Check if room has a pending progress timer"""
        return self.intervention_service.has_progress_timer(room_id)
    
    def get_active_progress_rooms(self):
        """Get list of rooms with active progress timers"""
        return self.intervention_service.get_active_progress_rooms()

    # Public methods for accessing intervention service functionality
    def cancel_pending_intervention(self, room_id: str, reason: str):
        """Public method to cancel pending interventions"""
        self.intervention_service.cancel_intervention(room_id, reason)

    def has_pending_timer(self, room_id: str) -> bool:
        """Check if room has a pending timer"""
        return self.intervention_service.has_pending_timer(room_id)

    def get_pending_timer_rooms(self) -> List[str]:
        """Get list of rooms with pending timers"""
        return list(self.intervention_service.pending_timers.keys())

    # Backward compatibility properties
    @property
    def pending_timers(self):
        """Backward compatibility access to pending timers"""
        return self.intervention_service.pending_timers

    def _cancel_pending_intervention(self, room_id: str, reason: str):
        """Backward compatibility method"""
        self.intervention_service.cancel_intervention(room_id, reason)


    def generate_scaffolding_with_tracking(self, room_id: str, comment_line: str, language: str, full_code: str = ""):
        """Generate scaffolding with proper tracking"""
        from .scaffolding_service import ScaffoldingService
        
        # Create service instance and generate scaffolding
        scaffolding_service = ScaffoldingService()
        result = scaffolding_service.generate_scaffolding(comment_line, language, full_code)
        
        # Track the activity with complete context
        self.track_scaffolding_activity(room_id, comment_line, language, result)
        
        return result

    def generate_todo_code_with_tracking(self, room_id: str, todo_line: str, language: str, full_code: str = "", problem_context: str = ""):
        """Generate TODO code with proper tracking"""
        from .todo_reveal_service import TodoRevealService
        
        # Create service instance and generate TODO code
        todo_reveal_service = TodoRevealService()
        result = todo_reveal_service.generate_todo_code(todo_line, language, full_code, problem_context)
        
        # Track the activity with complete context
        self.track_todo_reveal(room_id, todo_line, language, result)
        
        return result

# Global AI agent instance
ai_agent = None

def init_ai_agent(socketio_instance):
    """Initialize the AI agent"""
    global ai_agent
    ai_agent = AIAgent(socketio_instance)
    return ai_agent

def get_ai_agent():
    """Get the global AI agent instance"""
    return ai_agent
